<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="REINFORCE"><title>深度强化学习（DRL）算法 1</title><link rel=canonical href=https://amulil.github.io/p/hello-world/><link rel=stylesheet href=/scss/style.min.8191399262444ab68b72a18c97392f5349be20a1615d77445be51e974c144cff.css><meta property="og:title" content="深度强化学习（DRL）算法 1"><meta property="og:description" content="REINFORCE"><meta property="og:url" content="https://amulil.github.io/p/hello-world/"><meta property="og:site_name" content="阿姆姆姆姆姆姆姆"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="DRL"><meta property="article:tag" content="single agent"><meta property="article:published_time" content="2023-01-09T00:00:00+00:00"><meta property="article:modified_time" content="2023-01-09T00:00:00+00:00"><meta property="og:image" content="https://amulil.github.io/p/hello-world/cover.jpg"><meta name=twitter:title content="深度强化学习（DRL）算法 1"><meta name=twitter:description content="REINFORCE"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://amulil.github.io/p/hello-world/cover.jpg"></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu39ca060862f8ed744897e581c7710d5f_40123_300x0_resize_box_3.png width=300 height=304 class=site-logo loading=lazy alt=Avatar></a>
<span class=emoji>🏃</span></figure><div class=site-meta><h1 class=site-name><a href=/>阿姆姆姆姆姆姆姆</a></h1><h2 class=site-description>庾信平生无萧瑟，暮年诗赋动江关。</h2></div></header><ol class=social-menu><li><a href=https://github.com/amulil target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" width="64" height="64"><path d="M5.6875 5S5 6.207031 5 8.25c0 1.355469.308594 2.070313.53125 2.4375C3.96875 12.3125 3 14.515625 3 17.34375 3 24.585938 7.589844 27 16 27s13-2.414062 13-9.65625C29 14.417969 28.085938 12.21875 26.59375 10.625 26.964844 9.515625 27.382813 7.421875 26.34375 5c-3.101562.0-5.6875 2.382813-5.78125 2.46875C19.113281 7.152344 17.574219 7 16 7c-1.605469.0-3.179687.195313-4.65625.5625C9.265625 5.503906 6.757813 5 5.6875 5zm15 10.4375C21.53125 15.429688 22.3125 15.5 23 15.71875 24.832031 16.300781 26 17.984375 26 19.875 26 25.109375 23.191406 26 16 26 10.65625 26 6.3125 25.058594 6.3125 20.0625c0-1.90625 1.035156-2.984375 1.78125-3.65625 1.640625-1.476562 4.230469-.75 7.90625-.75 1.671875.0 3.277344-.203125 4.6875-.21875zM10.5 18C9.671875 18 9 18.894531 9 20s.671875 2 1.5 2S12 21.105469 12 20s-.671875-2-1.5-2zm11 0C20.671875 18 20 18.894531 20 20s.671875 2 1.5 2S23 21.105469 23 20s-.671875-2-1.5-2zm-11.15625.84375c.234375.0.40625.199218999999999.40625.4375s-.171875.4375-.40625.4375S9.90625 19.519531 9.90625 19.28125s.203125-.4375.4375-.4375zm11 0c.234375.0.40625.199218999999999.40625.4375s-.171875.4375-.40625.4375-.4375-.199218999999999-.4375-.4375.203125-.4375.4375-.4375z"/></svg></a></li><li><a href=https://www.zhihu.com/people/Zephyr1994 target=_blank title=Zhihu rel=me><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 256 256" width="32" height="32" fill-rule="nonzero"><g fill="#339af0" fill-rule="nonzero" stroke="none" stroke-width="1" stroke-linecap="butt" stroke-linejoin="miter" stroke-miterlimit="10" stroke-dashoffset="0" font-family="none" font-weight="none" font-size="none" text-anchor="none" style="mix-blend-mode:normal"><g transform="scale(8,8)"><path d="M30.62891 8.98828c-.36563.04219-.92969.21094-.92969.21094s-8.19961.9-11.59961 1c.1.5.40078.9.80078 1 .7.1 1.2.0 2.5.0 1.2-.1 2.19883-.09961 2.79883-.09961V16H18s.09922 1.19922 1.19922 1.19922h5v3.40039c0 .7-.49922 1.09961-1.19922 1.09961s-1.2-.09961-2-.09961c.1.2.20039.69961.90039 1.09961.5.2.79883.30078 1.29883.30078 1.5.0 2.30078-.90078 2.30078-2.30078v-3.5h6.09961c.4.0.40078-1.19961.30078-1.09961h-6.5v-4.90039c.2.0.59961-.09961 1.09961-.09961 2.1-.1 3.50039-.40039 4.40039-.40039.0.0.6-1.39922.0-1.69922-.05-.025-.14961-.02578-.27148-.01172zM3.30078 9s-1.20156-39e-5-1.60156 1.09961c-.1.4-.79922 2.00078-1.69922 3.80078.3.0 1.20078-.09961 1.80078-1.09961.1-.3.4-.50039.5-.90039h1.5c0 .5-.10156 3.60039-.10156 3.90039H1.09961C.49961 15.80078.30078 17 .30078 17H3.5c-.2 2.4-1.4 4.10078-3.5 5.80078 1 .3 1.99961-39e-5 2.59961-.40039.0.0 1.20078-.90078 1.80078-3.30078L6.90039 22s.40039-1.4-.09961-2c-.4-.5-1.20117-1.40078-1.70117-1.80078l-.69922.60156c.2-.7.40039-1.10078.40039-1.80078H8s-39e-5-1.19922-.40039-1.19922H4.90039c.1-1.3.09961-2.80039.09961-3.90039h2.40039S7.5 10.80078 7 10.80078H2.59961c.2-.7.40117-1.10078.70117-1.80078zM9 11v11h1.19922l.40039 1.30078L12.69922 22H15V11zm20.28711 1.17773c-.16875.00938-.33633.07266-.48633.22266L27 14.80078 28 15.5c1.1-1.3 2.30078-2.90039 2.30078-2.90039s-.50742-.45-1.01367-.42187zm-19.08789.02149h3.5v8.60156H12.5l-1.40039.89844-.29883-.89844h-.60156zM20.12891 12.34766c-.42187-.02813-.92969.25195-.92969.25195S21.20078 15.4 21.30078 15.5l1-.69922S21 13 20.5 12.5c-.1-.1-.23047-.14297-.37109-.15234z"/></g></g></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>主页</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>归档</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>搜索</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>暗色模式</span></li></div></ol></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/hello-world/><img src=/p/hello-world/cover_hud7e36f7e20e71be184458283bdae4646_55974_800x0_resize_q75_box.jpg srcset="/p/hello-world/cover_hud7e36f7e20e71be184458283bdae4646_55974_800x0_resize_q75_box.jpg 800w, /p/hello-world/cover_hud7e36f7e20e71be184458283bdae4646_55974_1600x0_resize_q75_box.jpg 1600w" width=800 height=534 loading=lazy alt="Featured image of post 深度强化学习（DRL）算法 1"></a></div><div class=article-details><header class=article-category><a href=/categories/rl/ style=background-color:#2a9d8f;color:#fff>强化学习</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/hello-world/>深度强化学习（DRL）算法 1</a></h2><h3 class=article-subtitle>REINFORCE</h3></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Jan 09, 2023</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>阅读时长: 3 分钟</time></div></footer></div></header><section class=article-content><blockquote><p>“养成习惯的过程可以分为四个简单的步骤：提示、渴求、反应和奖励。”</p><p>摘录来自《掌控习惯》詹姆斯·克利尔(James Clear) 此材料可能受版权保护。</p></blockquote><h1 id=前言>前言</h1><p>就像引言里所描述的养成习惯的四个步骤，如果我们想让机器也有自己的“习惯”，去掉机器没有的渴求属性，就是强化学习所做的事情 —— 帮机器养成“习惯”，而 DRL 就是使用深度学习的技术去实现强化学习算法。今天是系列文章的第一篇，会介绍最基础的 policy-based 的算法 —— REINFORCE。</p><p>τ = {s0, a0, r1, s1, a1, r2, s2, a2 &mldr; rT, sT, aT}, 那么根据 MDP 属性有:</p><p>$$ p(\tau) = \prod_{t=0}^{T}p_{\theta}(a_{t}|s_{t})p(s_{t+1}|s_{t}, a_{t}) $$</p><p>那么这里的 pθ 就是机器的策略，针对 s 会产生什么样的 a。因为当 s 和 a 都确定了，下一时刻的 s 是系统的固有属性，我们没办法控制，所以我们后面只关心 pθ 。
因为每一时刻的反应都会产生相应的回报，那么我们把每一时刻的回报加起来，就是这一系列反应产生的整体回报，我们用 R(τ) 表示。有了整体回报，我们就可以衡量机器行为的好坏。</p><p>$$R(\tau) = \sum_{t=1}^{T}r_{t}$$</p><p>机器应该更关心当下的回报还是未来的回报呢？我们引入系数 γ ，如果它是 0，我只关注当下，它的值越大，我们会越关心未来的回报。</p><p>$$R_{\theta} = E_{\tau\sim p_{\theta}(\tau)}[R(\tau)] = \sum_{\tau}p_{\theta}(\tau)R(\tau)$$</p><p>有了上面的信息，接下来我们只要使得机器的期望回报最大，我们的机器就会牛逼起来！</p><p>$$R_{\theta} = E_{\tau\sim p_{\theta}(\tau)}[R(\tau)] = \sum_{\tau}p_{\theta}(\tau)R(\tau)$$</p><h1 id=如何获得最大的期望回报>如何获得最大的期望回报？</h1><p>由上面的期望回报的公式，我们可以通过调节策略增大可以获得更大回报的反应的概率，可以用深度神经网络表示策略，把 s 输入神经网络（可以是MLP\CNN\LSTM\Transformer&mldr;）获得的输出就是每个反应的概率。s 输入到神经网络，得到 a，这里随机采样一个 a（为了探索，选最大的不一定是正确的） 然后得到下一时刻的 s，重复收集，就有了上面公式里的 τ，从而就积累了训练数据。那么有过机器学习经验的人，可以发现答案呼之欲出，就是求导，梯度下降是求最小值，那么求最大值就是加个负号。</p><p>$$\theta \leftarrow \theta + \alpha \nabla \bar{R}(\theta)$$</p><p>其中：</p><p>$$
\begin{aligned}
\nabla \bar{R}(\theta) & =\nabla_\theta \sum_\tau p(\tau) R(\tau) \
& =\sum_\tau \nabla_\theta p(\tau) R(\tau) \
& =\sum_\tau p(\tau) \frac{\nabla_\theta p(\tau)}{p(\tau)} R(\tau) \quad\left(\text { 因为 } \nabla_\theta \log (z)=\frac{1}{z} \nabla_\theta z\right) \
& =\sum_\tau p(\tau) \nabla_\theta \log p(\tau) R(\tau) \
& \approx \frac{1}{m} \sum_{i=1}^m \nabla_\theta \log p\left(\tau^{(i)}\right) R\left(\tau^{(i)}\right) \
& =\frac{1}{m} \sum_{i=1}^m \sum_{t=1}^T \nabla_\theta \log p_\theta\left(a_t^{(i)} \mid s_t^{(i)}\right) R\left(\tau^{(i)}\right) \
& =\frac{1}{m} \sum_{i=1}^m R\left(\tau^{(i)}\right) \sum_{t=1}^T \nabla_\theta \log p_\theta\left(a_t^{(i)} \mid s_t^{(i)}\right)
\end{aligned}
$$</p><h1 id=实现>实现</h1><p>实现很简单，这里结合参考很快就可以看懂。</p><h1 id=缺点>缺点</h1><p>方法很简单，虽然说大道至简，但是用上述方法训练出来的机器还是不够牛逼。主要是因为方法里存在一些缺陷：</p><ol><li>策略产生的 τ 不能再次用于训练，因为策略一直在更新，策略更新了，那么更新之前产生的 τ 就得丢掉了，训练效率很低。</li><li>τ 里的每个 a 用的都是同样的 R，更好的情况应该是每个 a 用一个 R。</li></ol><h1 id=改进>改进</h1><ul><li>针对 1，下一篇文章介绍的 PPO 提出了改进</li><li>针对 2：
我们可以这样设置 R（一种 Credit Assignment）：
$$R_{t}(\tau) = \sum_{t=t(a)}^{T}\gamma^{t-t(a)}r_{t},\gamma \in [0,1]$$</li></ul><h1 id=参考>参考</h1><ol><li>深度强化学习——李宏毅 <a class=link href="https://www.bilibili.com/video/BV1MW411w79n/?spm_id_from=333.337.search-card.all.click&vd_source=880886f42f0b8f6ed75679ffe50b5384" target=_blank rel=noopener>https://www.bilibili.com/video/BV1MW411w79n/?spm_id_from=333.337.search-card.all.click&vd_source=880886f42f0b8f6ed75679ffe50b5384</a></li><li>Deep Reinforcement Learning: Pong from Pixels <a class=link href=http://karpathy.github.io/2016/05/31/rl/ target=_blank rel=noopener>http://karpathy.github.io/2016/05/31/rl/</a></li><li><a class=link href=https://github.com/pytorch/examples/blob/main/reinforcement_learning/reinforce.py target=_blank rel=noopener>https://github.com/pytorch/examples/blob/main/reinforcement_learning/reinforce.py</a></li><li><a class=link href=https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/unit5/unit5.ipynb target=_blank rel=noopener>https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/unit5/unit5.ipynb</a></li><li>What does log_prob do? <a class=link href=https://stackoverflow.com/questions/54635355/what-does-log-prob-do target=_blank rel=noopener>https://stackoverflow.com/questions/54635355/what-does-log-prob-do</a></li></ol></section><footer class=article-footer><section class=article-tags><a href=/tags/drl/>DRL</a>
<a href=/tags/single-agent/>single agent</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css integrity="sha256-J+iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s=" crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js integrity="sha256-InsNdER1b2xUewP+pKCUJpkhiqwHgqiPXDlIk7GzBu4=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI=" crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.querySelector(`.article-content`),{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script></article><div class=disqus-container><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//hugo-theme-stack.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2023 阿姆姆姆姆姆姆姆</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.16.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>